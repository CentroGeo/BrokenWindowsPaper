[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BOOK_PAPER",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "Aquí va la introducción y algunos antecedentes Tener muy claro el planteamiento del problema Definir subsecciones"
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "2  Data Acquisition and Preprocessing",
    "section": "",
    "text": "3 Adquisition\nCenso de poblacion 2020\nDescarga masiva Manzanas"
  },
  {
    "objectID": "data.html#índice-de-concentración-de-desventajas",
    "href": "data.html#índice-de-concentración-de-desventajas",
    "title": "2  Data Acquisition and Preprocessing",
    "section": "5.1 Índice de concentración de desventajas",
    "text": "5.1 Índice de concentración de desventajas\nConstruido a partir de cuatro dimensiónes (con base a censo 2010) y reducidad a una componente principal por PCA. Las dimensiones que se exponen en el articulo son: - Porcentaje de masculinos de 15 a 29 - Porcentaje de población sin servicios a salud - Promedio de habitantes que ocupan un hogar privado - Porcentaje de personas que hablan una lengua indigena\nCon base al Censo de población de 2020, las dimensiones se resumen de la forma:\n\n\n\n\n\nClave\nDescripción\n\n\n\n\nP_15A17_M\nPoblación masculina de 15 a 17 años\n\n\nP_18A24_M\nPoblación masculina de 18 a 24 años\n\n\nPSINDER\nPoblación sin afiliación a servicios de salud\n\n\nPROM_OCUP\nPromedio de ocupantes en viviendas particulares habitadas\n\n\nP3YM_HLI\nPoblación de 3 años y más que habla alguna lengua indígena\n\n\n\n\n\n\n\nLa primer parte consta de cargar la base de datos de censo, seleccionar las dimensiones, limpiar la información y preparala para poder hacerla únion de estas en la geometry de la unidd geografica manzanas. Se cargan las librerias necesarias.\n\n\n\n## Librerias \n\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\nimport contextily as ctx\nimport matplotlib.pyplot as plt\nfrom IPython.display import Markdown\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\n### Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nSe carga la información del Censo por unidad manzanas conservando unicamente los campos de interes: ENTIDAD, NOM_ENT, MUN, NOM_MUN LOC, NOM_LOC, AGEB, MZA, POBTOT, P_15A17_M, P_18A24_M, PSINDER, PROM_OCUP y P3YM_HLI\n\n\nCENSO_2020 =  pd.read_csv(Entradas + 'MANZANAS.csv', encoding = 'Latin-1')\nCENSO_2020 = CENSO_2020 [['ENTIDAD','NOM_ENT','MUN',\n                          'NOM_MUN','LOC','NOM_LOC',\n                          'AGEB','MZA','POBTOT', \n                          'P_15A17_M','P_18A24_M','PSINDER',\n                          'PROM_OCUP', 'P3YM_HLI']]\n\nCENSO_2020.head(2)                          \n\n\nDe la base de datos filtramos eliminando las filas que contienen los totales\n\n\nValues = ['Total de la entidad','Total del municipio',\n         'Total de la localidad urbana', 'Total AGEB urbana']\nCENSO_2020_USE = CENSO_2020.query(\"NOM_LOC != @Values\")\n\nCENSO_2020_USE.head(2)\n\n\nDentro de la base de datos existe la presencia de filas donde los valores son simbolos o caracteres especiales(*, N/D, 99999, etc), por lo que es necesario remplazarlos por valores NAN.\n\n\nCENSO_2020_USE = CENSO_2020_USE.replace({'999999999': np.nan, \n                                         '99999999': np.nan,\n                                         '*': np.nan,\n                                         'N/D': np.nan})\n                  \nDIM_NUM = CENSO_2020_USE.iloc[: , -6:].columns.tolist()\nDIM_TEXT = CENSO_2020_USE.iloc[:, :8].columns.tolist()\n\nCENSO_2020_USE[DIM_NUM] = CENSO_2020_USE[DIM_NUM].astype('float')\nCENSO_2020_USE[DIM_TEXT] = CENSO_2020_USE[DIM_TEXT].astype(str)\n\n\nDe igual manera la información referida a a las columnas de “Entidad, Municipio, Localidad, AGEB y Manzana”, no presetan el formato necesario para crear la columna CVEGEO, por lo que debemos completar la información de la forma correcta.\n\n\nCreada la columna CVEGEO, calculamos la dimensión población masculina de 15 a 24 años como la suma de “P_15A17_M y P_18A24_M”. Una vez que hemos creado la dimensión se hacen poco necesarias “P_15A17_M y P_18A24_M, por lo que se eliminan.\n\n\n## Corrección de información\nCENSO_2020_USE['ENTIDAD'] = CENSO_2020_USE['ENTIDAD'].str.zfill(2)\nCENSO_2020_USE['MUN'] = CENSO_2020_USE['MUN'].str.zfill(3)\nCENSO_2020_USE['LOC'] = CENSO_2020_USE['LOC'].str.zfill(4)\nCENSO_2020_USE['AGEB'] = CENSO_2020_USE['AGEB'].str.zfill(4)  \nCENSO_2020_USE['MZA'] = CENSO_2020_USE['MZA'].str.zfill(3)\n\nCENSO_2020_USE['CVEGEO'] = CENSO_2020_USE[['ENTIDAD', 'MUN',\n                                           'LOC','AGEB','MZA']].agg(''.join, axis=1)\n\n## Cálculo de Población masculina de 15 a 24 años\nCENSO_2020_USE['P_15A24_M'] = CENSO_2020_USE[[\"P_15A17_M\", \n                                              \"P_18A24_M\"]].sum(axis=1, \n                                                                min_count=1)\n\n## Eliminación de dimensiones\nCENSO_2020_USE = CENSO_2020_USE.drop(['P_15A17_M','P_18A24_M'], axis = 1)\n\nCENSO_2020_USE.head(2)\n\n\nSe carga la base de datos geoespacial que corresponde a la unidad geografica de “manzanas”. Para este caso, el archivo se encuentra en formato “json”. Del archivo, unicamente consideramos las columnas “CVEGEO y geometry”\n\n\n### Se carga el archivo espacial de Manzanas\n\nMANZA_CDMX = gpd.read_file(Entradas +'MANZA_CDMX.json')\nMANZA_CDMX = MANZA_CDMX[['CVEGEO','geometry']]\nMANZA_CDMX.head(2)\n\n\nUnion (merge) de las unidades geoespaciales con la información del Censo de Población y vivienda 2020. En este punto a cada unidad geografica le asignamos la información del censo de población.\n\n\n### Union a la izquierda con campo llave primaria \"CVEGEO\"\nMERGE = MANZA_CDMX.merge( CENSO_2020_USE,\n                          left_on = 'CVEGEO',\n                          right_on = 'CVEGEO',\n                          how = 'inner')\nMERGE.head(2)          \n\n\nSiempre es importante saber en que sistema de proyección se encuentran nuestros datos, para eso usamos “crs”\n\n\nMERGE.crs\n\n\nHacemos un mapa por que nos gustan los mapitas.\n\n\nfig, ax = plt.subplots(figsize=(8, 8))\nax = MERGE.plot(ax = ax, column='P_15A24_M',\n                legend=False,\n                alpha=0.8,\n                scheme='NaturalBreaks',\n                cmap='copper',\n                classification_kwds={'k':6})\nax.set(title='Población Masculina 15 a 24 años, Ciudad de México')\n\nax.set_axis_off()\n\nplt.show()\n\n\nHasta el punto anterior tenemos la información contenida dentro de las manzanas, el paso que sigue es llevar las manzanas a colonias. Para esto es necesario entender que ambos elementos son poligonales y que los centroides de manzanas no necesariamente refieren a la solución contenida dentro de un poligono mayor.\n\n\nPor eso es necesario usar el criterio de maxima área de la sobreposición de poligonos. Al hablar de área el sistema de proyección debe estar en metros, por lo que si no lo esta se debe cambiar. Para este caso se cambio a EPSG:6362\n\n\nSe cargan las colonias y se valida que ambos crs se encuentren en metros “6362 o 6362” , en caso contrario es necesrio llevar a cabo una reproyección.\n\n\nCOLONIAS_CDMX = gpd.read_file(Entradas +'COLONIAS.json')\nprint(\"Colonias CRS\", COLONIAS_CDMX.crs)\nprint(\"Manzanas CRS\", MERGE.crs)\n\n\nLos archivos estan en coordenadas geograficas, por lo que se reproyecta\n\n\nMANZANA_METROS = MERGE.to_crs(6362)\nCOLONIAS_METROS = COLONIAS_CDMX.to_crs(6362)\n\nprint(\"Crs Manzanas\", MANZANA_METROS.crs )\nprint(\"Crs Colonias\", COLONIAS_METROS.crs )\n\n\nBuscamos en este punto identificar la intersección entre colonias y manzanas para asignar a cada manzana (base al criterio de área maxima) la clave de la colonia a la que pertence.\n\n\nINTERSECCION = gpd.overlay(COLONIAS_METROS,\n                           MANZANA_METROS,\n                            how = 'intersection')\n\n\nSe calcula el valor de área para cada poligono intersectado\n\n\nINTERSECCION['area'] = INTERSECCION.geometry.area\n\n\nPara el overlay se reordena la información del área de manera descendente y se eliminan los duplicados con base a la “CVEGEO” manteniendo unicamente el primer valor\n\n\nINTERSECCION = (INTERSECCION.sort_values('area', ascending = False).\n                drop_duplicates(subset=\"CVEGEO\", keep = 'first').\n                drop(['geometry','area'], axis = 1))\n\n### Se eliminan columnas no necesarias\nINTERSECCION_USE = INTERSECCION.drop(['ENT', 'CVEDT', 'NOMDT', 'DTTOLOC'], axis = 1)\n\n\nEn la base de colonias se identificaron caracteres especiales, por lo que se procede a remplazarlos, por su valor correspondiente.\n\n\nDic_Ca = {'Ã‘': 'Ñ'}\nINTERSECCION_USE.replace(Dic_Ca, inplace=True, regex=True)\nINTERSECCION_USE.columns = INTERSECCION_USE.columns.to_series().replace(Dic_Ca, regex=True)\n\nINTERSECCION_USE.shape\n\n\nSe une la información de overly de las Manzanas ya alineadas con colonias en la geometry de las manzanas para tener la base final. En la base final podemos observar la información a nivel: manzana, colonia y alcaldia, donde esta ultima se extraer en razon directa de la informacion contenida en la base de manzanas.\n\n\nDATA_FINAL_USE = MANZA_CDMX.merge(INTERSECCION_USE,\n                          left_on = 'CVEGEO',\n                          right_on = 'CVEGEO',\n                          how = 'inner').rename({\"CVEUT\": \"CVE_COL\", \"NOMUT\": \"NOM_COL\", \"ID\": \"ID_COL\"}, axis = 1)\nDATA_FINAL_USE.shape\n\n\nSe valida que cada manzana este asociada a cada una de las colonias\nRecorndado que la relación es una colonia a muchas manzanzanas\n“” Por lo que no deben existir manzanas repetididas”\n\n\\[M_{n-1} = f(C)\\] \\[ C \\gets M_{n-1}\\]\n\nSe valida que no existan manzanas repetidas\n\n\nDATA_FINAL_USE.CVEGEO.value_counts()\n\n\nLa relacion de muchas manzanas a una colonia, se valida para cada clave de colonias se repite tantas veces existan manzanas\n\n\nDATA_FINAL_USE.CVE_COL.value_counts()\n\n\nAqui validamos como las claves de las manzanas son diferentes para una misma colonia y se entiende la relacion, muchas manzanas a una colonia\n\n\nDATA_FINAL_USE.query('CVE_COL == \"07-320\"').head(3)\n\n\nReordenamos la información de la forma “Regional a local” es decir:\n\n\\[ Alcaldia \\to Colonia \\to Manzana \\]\n\nAlcaldia: ENTIDAD, NOM_ENT, MUN, NOM_MUN, LOC, NOM_LOC,\n\nColonia: ID_COL, CVE_COL, NOM_COL,\nManzana: AGEB, MZA, CVEGEO,\nDimensiones: POBTOT, PSINDER, PROM_OCUP, P3YM_HLI, P_15A24_M\nGeometry\n\n\nReordenamiento de la información\n\n\nDATA_FIN_USE = DATA_FINAL_USE[['ENTIDAD','NOM_ENT', 'MUN', 'NOM_MUN', 'LOC', 'NOM_LOC',\n                               'ID_COL','CVE_COL', 'NOM_COL', 'AGEB', 'MZA',\n                               'POBTOT', 'PSINDER', 'PROM_OCUP', 'P3YM_HLI', 'P_15A24_M',\n                               'geometry']]\n\nDATA_FIN_USE.head(3)\n\n\nHacemos un mapita porque nos gustan los mapitas\n\n\nfig, ax = plt.subplots(figsize=(8, 8))\nax = DATA_FIN_USE.plot(ax = ax, column='P_15A24_M',\n                       legend= False,\n                       alpha=0.8,\n                       scheme='NaturalBreaks',\n                       cmap='copper',\n                       classification_kwds={'k':6})\nax.set(title='Población Masculina 15 a 24 años, Ciudad de México')\n\nax.set_axis_off()\n\nplt.show()"
  },
  {
    "objectID": "data.html#análisis-de-componentes-principales-pca",
    "href": "data.html#análisis-de-componentes-principales-pca",
    "title": "2  Data Acquisition and Preprocessing",
    "section": "5.2 Análisis de Componentes Principales (PCA)",
    "text": "5.2 Análisis de Componentes Principales (PCA)\n\nEn esta sección se cálcula el indice de Concetración de desventajas mediante la reducción de las dimensiónes por componentes principales (PCA). Esto se hace a nivel Alcaldias y Delegaciones. La información a nivel alcaldia y delegacion es un proceso de reagrupacion y nuevos calculos de los valores.\n\n\n5.2.1 NIVEL COLONIAS\n\nPara este punto agrupamos los datos por nivel colonia para extraer el valor del índice por “PCA”\n\n\nCOLONIA_PCA = pd.DataFrame(DATA_FIN_USE.groupby(['CVE_COL']).agg({'POBTOT': 'sum', \n                                                                  'PSINDER':'sum',\n                                                                  'PROM_OCUP': 'mean',\n                                                                  'P3YM_HLI':'sum',\n                                                                  'P_15A24_M': 'sum'}).reset_index())\nCOLONIA_PCA.head(2)\n\n\n\n\n\n\n\nImpotante\n\n\n\nPara que componentes principales tenga un alto rendimiento la información sdebe estar normalizada por Z-SCORE (StandardScaler)\n\\[ Z = \\frac{x - \\mu}{\\sigma} \\]\n\n\n\nPara calcular la componente principal, separamos nuestra base de datos con el fin de tener las dimensiones que contruyen el índice.\n\n\n### Hacemos un copia por si necesitamos un proceso con la base original\nPCA_COLONIAS = COLONIA_PCA.copy()\n\n### Seleccion de las dimensiones con las que se calcula el indice de desventajas \"PSINDER; PROM_OCUP; P3YM_HLI; P_15A24_M\"\n\nPCA_X = PCA_COLONIAS.drop(['CVE_COL','POBTOT'], axis = 1)\nPCA_y = PCA_COLONIAS[['CVE_COL']]\n\n\nSe normaliza la informacion por Z-Score, determinamos el número de componentes y aplicamos la función para calcular\n\n\n### Se normaliza la informacion por Z-Score\n\nS_TRANSF = StandardScaler()\nPCA_X_SCALER = pd.DataFrame(S_TRANSF.fit_transform(PCA_X), \n                            columns = PCA_X.columns)\n\n### Se determina el número de componentes\nPCA_N = PCA(n_components = 1)\nPCA_COMPONENTE = PCA_N.fit_transform(PCA_X_SCALER)\n\n\nSe calcula la varianza total por respecto al numero de componentes\n\n\n### Se calcula la varianza total por respecto al numero de componentes\nVARIANZA_TOTA = PCA_N.explained_variance_ratio_.sum() * 100\nprint(\"\\n Total de la variancia explicada \\n\", round(VARIANZA_TOTA,3), \"%\")\n\n\nCon una componente (PC1) se explica 66.82 % de la varianza total, lo cual implica que mas de la mitad de la información e los datos puede encapsularse en ese componente principal.\n\n\nfinalmente se indexan los resultados a la base de datos como una nueva columna con clave DIS_COL = concentrated disadvantage component\n\n\n### Pegamos los valores de PCA en la base de datos\nPCA_COLONIAS['DIS_COL'] = PCA_COMPONENTE\nPCA_COLONIAS.head(5)\n\n\n\n\n\n\n\nImpotante\n\n\n\nLo anterior lo transformamos a una funcion para optimizar el proceso de trabajo. Funcion que podemos llamar despues\n\n\n\ndef CONC_DIS (TABLA, DIM_CLAVE, DIM_POBLA):\n    \n    PCA_TABLA = TABLA.copy()\n    \n    ### Seleccion de las dimensiones con las que se calcula el indice de desventajas \"PSINDER; PROM_OCUP; P3YM_HLI; P_15A24_M\"\n     \n    PCA_X = PCA_TABLA.drop([DIM_CLAVE, DIM_POBLA], axis = 1)\n    PCA_y = PCA_TABLA[[DIM_CLAVE]]\n    \n    ### Se normaliza la informacion por Z-Score\n    \n    S_TRANSF = StandardScaler()\n    PCA_X_SCALER = pd.DataFrame( S_TRANSF.fit_transform(PCA_X), \n                                 columns = PCA_X.columns)\n                                 \n    ### Se determina el número de componentes\n    \n    PCA_N = PCA(n_components = 1)\n    PCA_COMPONENTE = PCA_N.fit_transform(PCA_X_SCALER)\n    \n    ### Se calcula la varianza total por respecto al numero de componentes\n     \n    VARIANZA_TOTA = PCA_N.explained_variance_ratio_.sum() * 100\n\n    print(\"\\n Total de la variancia explicada \\n\", round(VARIANZA_TOTA,3), \"%\")\n    ### Se indexan los resultados a la base de datos como una nueva columna con clave DIS_COL = concentrated disadvantage component \n    \n    PCA_TABLA['DISAD'] = PCA_COMPONENTE\n\n    PCA_TABLA = PCA_TABLA[[DIM_CLAVE, 'DISAD' ]]\n\n    return (PCA_TABLA)\n\n\nPodemos usar la función creada y aplicarla en los datos para revalidar los resultados.\n\n\n### Revalidación de información\n\nDESVE_COL = CONC_DIS (COLONIA_PCA, 'CVE_COL','POBTOT')\nDESVE_COL.head(2)\n\n\n\n5.2.2 NIVEL ALCALIDAS\n\nEl Agrupamiento de datos por nivel Alcaldia para “PCA”. Recordando que la clave de Alcaldia == Municipio la podemos observar de la forma: DATA_FIN_USE.NOM_MUN.value_counts()\n\n\nALCALDIA_PCA = pd.DataFrame(DATA_FIN_USE.groupby(['MUN']).agg({'POBTOT': 'sum', \n                                                                  'PSINDER':'sum',\n                                                                  'PROM_OCUP': 'mean',\n                                                                  'P3YM_HLI':'sum',\n                                                                  'P_15A24_M': 'sum'}).reset_index())\nALCALDIA_PCA.head(2)\n\n\nAplicamos la funcion creada con anterioridad\n\n\n### Aplicando la función creada arriba\n\nDESVE_ALCA = CONC_DIS (ALCALDIA_PCA, 'MUN','POBTOT')\nDESVE_ALCA.head(2)\n\n\nEn este punto, podemos unir toda la información a la tabla original y renombramos las columnas de desventajas en cada nivel\n\n\nMERGE_DESVENTAJAS = DATA_FIN_USE.merge(DESVE_COL, \n                                       left_on = 'CVE_COL', \n                                       right_on = 'CVE_COL', \n                                       how = 'inner').merge(DESVE_ALCA, \n                                                            left_on ='MUN', \n                                                            right_on = 'MUN' , \n                                                            how = 'inner').rename({\"DISAD_x\": \"DIS_COL\", \"DISAD_y\": \"DIS_MUN\"}, axis = 1)\n\nMERGE_DESVENTAJAS.head(2)\n\n\nHacemos un mapita nuevamente\n\n\nfig, ax = plt.subplots(figsize=(8, 8))\nax = MERGE_DESVENTAJAS.plot(ax = ax, column='DIS_COL',\n                            legend= True,\n                            alpha=0.8,\n                            scheme='NaturalBreaks',\n                            cmap='copper',\n                            classification_kwds={'k':6})\nax.set(title='Desventajas a nivel Colonia, Ciudad de México')\n\nax.set_axis_off()\n\nplt.show()\n\n\nfig, ax = plt.subplots(figsize=(8, 8))\nax = MERGE_DESVENTAJAS.plot(ax = ax, column='DIS_MUN',\n                            legend= True,\n                            alpha=0.8,\n                            scheme='NaturalBreaks',\n                            cmap='copper',\n                            classification_kwds={'k':6})\nax.set(title='Desventajas a nivel Alcaldias, Ciudad de México')\n\nax.set_axis_off()\n\nplt.show()"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "4  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  }
]