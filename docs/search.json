[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BOOK_PAPER",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "Aquí va la introducción y algunos antecedentes Tener muy claro el planteamiento del problema Definir subsecciones"
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "2  Data Acquisition and Preprocessing",
    "section": "",
    "text": "3 Adquisition\nCenso de poblacion 2020\nDescarga masiva Manzanas\nLlamadas del 911"
  },
  {
    "objectID": "data.html#concentración-de-desventajas",
    "href": "data.html#concentración-de-desventajas",
    "title": "2  Data Acquisition and Preprocessing",
    "section": "4.1 Concentración de desventajas",
    "text": "4.1 Concentración de desventajas\nConstruido a partir de cuatro dimensiónes (con base a censo 2010) y reducidad a una componente principal por PCA. Las dimensiones que se exponen en el articulo son: - Porcentaje de masculinos de 15 a 29 - Porcentaje de población sin servicios a salud - Promedio de habitantes que ocupan un hogar privado - Porcentaje de personas que hablan una lengua indigena\nCon base al Censo de población de 2020, las dimensiones se resumen de la forma:\n\n\n\n\n\nClave\nDescripción\n\n\n\n\nP_15A17_M\nPoblación masculina de 15 a 17 años\n\n\nP_18A24_M\nPoblación masculina de 18 a 24 años\n\n\nPSINDER\nPoblación sin afiliación a servicios de salud\n\n\nPROM_OCUP\nPromedio de ocupantes en viviendas particulares habitadas\n\n\nP3YM_HLI\nPoblación de 3 años y más que habla alguna lengua indígena\n\n\n\n\n\n\n\nLa primer parte consta de cargar la base de datos de censo, seleccionar las dimensiones, limpiar la información y preparala para poder hacerla únion de estas en la geometry de la unidd geografica manzanas. Se cargan las librerias necesarias.\n\n\n\n## Librerias \n\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\nimport contextily as ctx\nimport matplotlib.pyplot as plt\nfrom IPython.display import Markdown\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\n### Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nSe carga la información del Censo por unidad manzanas conservando unicamente los campos de interes: ENTIDAD, NOM_ENT, MUN, NOM_MUN LOC, NOM_LOC, AGEB, MZA, POBTOT, P_15A17_M, P_18A24_M, PSINDER, PROM_OCUP y P3YM_HLI\n\n\nCENSO_2020 =  pd.read_csv(Entradas + 'MANZANAS.csv', encoding = 'Latin-1')\nCENSO_2020 = CENSO_2020 [['ENTIDAD','NOM_ENT','MUN',\n                          'NOM_MUN','LOC','NOM_LOC',\n                          'AGEB','MZA','POBTOT', \n                          'P_15A17_M','P_18A24_M','PSINDER',\n                          'PROM_OCUP', 'P3YM_HLI']]\n\nCENSO_2020.head(2)                          \n\n\n\n\n\n  \n    \n      \n      ENTIDAD\n      NOM_ENT\n      MUN\n      NOM_MUN\n      LOC\n      NOM_LOC\n      AGEB\n      MZA\n      POBTOT\n      P_15A17_M\n      P_18A24_M\n      PSINDER\n      PROM_OCUP\n      P3YM_HLI\n    \n  \n  \n    \n      0\n      9\n      Ciudad de México\n      0\n      Total de la entidad Ciudad de México\n      0\n      Total de la entidad\n      0\n      0\n      9209944\n      193870\n      496288\n      2502789\n      3.32\n      125153\n    \n    \n      1\n      9\n      Ciudad de México\n      2\n      Azcapotzalco\n      0\n      Total del municipio\n      0\n      0\n      432205\n      8382\n      21785\n      90370\n      3.21\n      3208\n    \n  \n\n\n\n\n\nDe la base de datos filtramos eliminando las filas que contienen los totales\n\n\nValues = ['Total de la entidad','Total del municipio',\n         'Total de la localidad urbana', 'Total AGEB urbana']\nCENSO_2020_USE = CENSO_2020.query(\"NOM_LOC != @Values\")\n\nCENSO_2020_USE.head(2)\n\n\nDentro de la base de datos existe la presencia de filas donde los valores son simbolos o caracteres especiales(*, N/D, 99999, etc), por lo que es necesario remplazarlos por valores NAN.\n\n\nCENSO_2020_USE = CENSO_2020_USE.replace({'999999999': np.nan, \n                                         '99999999': np.nan,\n                                         '*': np.nan,\n                                         'N/D': np.nan})\n                  \nDIM_NUM = CENSO_2020_USE.iloc[: , -6:].columns.tolist()\nDIM_TEXT = CENSO_2020_USE.iloc[:, :8].columns.tolist()\n\nCENSO_2020_USE[DIM_NUM] = CENSO_2020_USE[DIM_NUM].astype('float')\nCENSO_2020_USE[DIM_TEXT] = CENSO_2020_USE[DIM_TEXT].astype(str)\n\n\nDe igual manera la información referida a a las columnas de “Entidad, Municipio, Localidad, AGEB y Manzana”, no presetan el formato necesario para crear la columna CVEGEO, por lo que debemos completar la información de la forma correcta.\n\n\nCreada la columna CVEGEO, calculamos la dimensión población masculina de 15 a 24 años como la suma de “P_15A17_M y P_18A24_M”. Una vez que hemos creado la dimensión se hacen poco necesarias “P_15A17_M y P_18A24_M, por lo que se eliminan.\n\n\n## Corrección de información\nCENSO_2020_USE['ENTIDAD'] = CENSO_2020_USE['ENTIDAD'].str.zfill(2)\nCENSO_2020_USE['MUN'] = CENSO_2020_USE['MUN'].str.zfill(3)\nCENSO_2020_USE['LOC'] = CENSO_2020_USE['LOC'].str.zfill(4)\nCENSO_2020_USE['AGEB'] = CENSO_2020_USE['AGEB'].str.zfill(4)  \nCENSO_2020_USE['MZA'] = CENSO_2020_USE['MZA'].str.zfill(3)\n\nCENSO_2020_USE['CVEGEO'] = CENSO_2020_USE[['ENTIDAD', 'MUN',\n                                           'LOC','AGEB','MZA']].agg(''.join, axis=1)\n\n## Cálculo de Población masculina de 15 a 24 años\nCENSO_2020_USE['P_15A24_M'] = CENSO_2020_USE[[\"P_15A17_M\", \n                                              \"P_18A24_M\"]].sum(axis=1, \n                                                                min_count=1)\n\n## Eliminación de dimensiones\nCENSO_2020_USE = CENSO_2020_USE.drop(['P_15A17_M','P_18A24_M'], axis = 1)\n\nCENSO_2020_USE.head(2)\n\n\nSe carga la base de datos geoespacial que corresponde a la unidad geografica de “manzanas”. Para este caso, el archivo se encuentra en formato “json”. Del archivo, unicamente consideramos las columnas “CVEGEO y geometry”\n\n\n### Se carga el archivo espacial de Manzanas\n\nMANZA_CDMX = gpd.read_file(Entradas +'MANZA_CDMX.json')\nMANZA_CDMX = MANZA_CDMX[['CVEGEO','geometry']]\nMANZA_CDMX.head(2)\n\n\nUnion (merge) de las unidades geoespaciales con la información del Censo de Población y vivienda 2020. En este punto a cada unidad geografica le asignamos la información del censo de población.\n\n\n### Union a la izquierda con campo llave primaria \"CVEGEO\"\nMERGE = MANZA_CDMX.merge( CENSO_2020_USE,\n                          left_on = 'CVEGEO',\n                          right_on = 'CVEGEO',\n                          how = 'inner')\nMERGE.head(2)          \n\n\nSiempre es importante saber en que sistema de proyección se encuentran nuestros datos, para eso usamos “crs”\n\n\nMERGE.crs\n\n\nHacemos un mapa por que nos gustan los mapitas.\n\n\nfig, ax = plt.subplots(figsize=(8, 8))\nax = MERGE.plot(ax = ax, column='P_15A24_M',\n                legend=False,\n                alpha=0.8,\n                scheme='NaturalBreaks',\n                cmap='copper',\n                classification_kwds={'k':6})\nax.set(title='Población Masculina 15 a 24 años, Ciudad de México')\n\nax.set_axis_off()\n\nplt.show()\n\n\nHasta el punto anterior tenemos la información contenida dentro de las manzanas, el paso que sigue es llevar las manzanas a colonias. Para esto es necesario entender que ambos elementos son poligonales y que los centroides de manzanas no necesariamente refieren a la solución contenida dentro de un poligono mayor.\n\n\nPor eso es necesario usar el criterio de maxima área de la sobreposición de poligonos. Al hablar de área el sistema de proyección debe estar en metros, por lo que si no lo esta se debe cambiar. Para este caso se cambio a EPSG:6362\n\n\nSe cargan las colonias y se valida que ambos crs se encuentren en metros “6362 o 6362” , en caso contrario es necesrio llevar a cabo una reproyección.\n\n\nCOLONIAS_CDMX = gpd.read_file(Entradas +'COLONIAS.json')\nprint(\"Colonias CRS\", COLONIAS_CDMX.crs)\nprint(\"Manzanas CRS\", MERGE.crs)\n\n\nLos archivos estan en coordenadas geograficas, por lo que se reproyecta\n\n\nMANZANA_METROS = MERGE.to_crs(6362)\nCOLONIAS_METROS = COLONIAS_CDMX.to_crs(6362)\n\nprint(\"Crs Manzanas\", MANZANA_METROS.crs )\nprint(\"Crs Colonias\", COLONIAS_METROS.crs )\n\n\nBuscamos en este punto identificar la intersección entre colonias y manzanas para asignar a cada manzana (base al criterio de área maxima) la clave de la colonia a la que pertence.\n\n\nINTERSECCION = gpd.overlay(COLONIAS_METROS,\n                           MANZANA_METROS,\n                            how = 'intersection')\n\n\nSe calcula el valor de área para cada poligono intersectado\n\n\n## Se calcula el area \nINTERSECCION['area'] = INTERSECCION.geometry.area\n\n\nPara el overlay se reordena la información del área de manera descendente y se eliminan los duplicados con base a la “CVEGEO” manteniendo unicamente el primer valor\n\n\nINTERSECCION = (INTERSECCION.sort_values('area', ascending = False).\n                drop_duplicates(subset=\"CVEGEO\", keep = 'first').\n                drop(['geometry','area'], axis = 1))\n\n### Se eliminan columnas no necesarias\nINTERSECCION_USE = INTERSECCION.drop(['ENT', 'CVEDT', 'NOMDT', 'DTTOLOC'], axis = 1)\n\n\nEn la base de colonias se identificaron caracteres especiales, por lo que se procede a remplazarlos, por su valor correspondiente.\n\n\nDic_Ca = {'Ã‘': 'Ñ'}\nINTERSECCION_USE.replace(Dic_Ca, inplace=True, regex=True)\nINTERSECCION_USE.columns = INTERSECCION_USE.columns.to_series().replace(Dic_Ca, regex=True)\n\nINTERSECCION_USE.shape\n\n\nSe une la información de overly de las Manzanas ya alineadas con colonias en la geometry de las manzanas para tener la base final. En la base final podemos observar la información a nivel: manzana, colonia y alcaldia, donde esta ultima se extraer en razon directa de la informacion contenida en la base de manzanas.\n\n\nDATA_FINAL_USE = MANZA_CDMX.merge(INTERSECCION_USE,\n                          left_on = 'CVEGEO',\n                          right_on = 'CVEGEO',\n                          how = 'inner').rename({\"CVEUT\": \"CVE_COL\", \"NOMUT\": \"NOM_COL\", \"ID\": \"ID_COL\"}, axis = 1)\nDATA_FINAL_USE.shape\n\n\nSe valida que cada manzana este asociada a cada una de las colonias\nRecorndado que la relación es una colonia a muchas manzanzanas\n“” Por lo que no deben existir manzanas repetididas”\n\n\\[M_{n-1} = f(C)\\] \\[ C \\gets M_{n-1}\\]\n\nSe valida que no existan manzanas repetidas\n\n\nDATA_FINAL_USE.CVEGEO.value_counts()\n\n\nLa relacion de muchas manzanas a una colonia, se valida para cada clave de colonias se repite tantas veces existan manzanas\n\n\nDATA_FINAL_USE.CVE_COL.value_counts()\n\n\nAqui validamos como las claves de las manzanas son diferentes para una misma colonia y se entiende la relacion, muchas manzanas a una colonia\n\n\nDATA_FINAL_USE.query('CVE_COL == \"07-320\"').head(3)\n\n\nReordenamos la información de la forma “Regional a local” es decir:\n\n\\[ Alcaldia \\to Colonia \\to Manzana \\]\n\nAlcaldia: ENTIDAD, NOM_ENT, MUN, NOM_MUN, LOC, NOM_LOC,\n\nColonia: ID_COL, CVE_COL, NOM_COL,\nManzana: AGEB, MZA, CVEGEO,\nDimensiones: POBTOT, PSINDER, PROM_OCUP, P3YM_HLI, P_15A24_M\nGeometry\n\n\nReordenamiento de la información\n\n\nDATA_FIN_USE = DATA_FINAL_USE[['ENTIDAD','NOM_ENT', 'MUN', 'NOM_MUN', 'LOC', 'NOM_LOC',\n                               'ID_COL','CVE_COL', 'NOM_COL', 'AGEB', 'MZA',\n                               'POBTOT', 'PSINDER', 'PROM_OCUP', 'P3YM_HLI', 'P_15A24_M',\n                               'geometry']]\n\nDATA_FIN_USE.head(3)\n\n\nHacemos un mapita porque nos gustan los mapitas\n\n\nfig, ax = plt.subplots(figsize=(8, 8))\nax = DATA_FIN_USE.plot(ax = ax, column='P_15A24_M',\n                       legend= False,\n                       alpha=0.8,\n                       scheme='NaturalBreaks',\n                       cmap='copper',\n                       classification_kwds={'k':6})\nax.set(title='Población Masculina 15 a 24 años, Ciudad de México')\n\nax.set_axis_off()\n\nplt.show()\n\n\n4.1.1 Análisis de Componentes Principales (PCA)\n\nEn esta sección se cálcula el indice de Concetración de desventajas mediante la reducción de las dimensiónes por componentes principales (PCA). Esto se hace a nivel Alcaldias y Delegaciones. La información a nivel alcaldia y delegacion es un proceso de reagrupacion y nuevos calculos de los valores.\n\n\n\n4.1.2 Nivel Colonias\n\nPara este punto agrupamos los datos por nivel colonia para extraer el valor del índice por “PCA”\n\n\nCOLONIA_PCA = pd.DataFrame(DATA_FIN_USE.groupby(['CVE_COL']).agg({'POBTOT': 'sum', \n                                                                  'PSINDER':'sum',\n                                                                  'PROM_OCUP': 'mean',\n                                                                  'P3YM_HLI':'sum',\n                                                                  'P_15A24_M': 'sum'}).reset_index())\nCOLONIA_PCA.head(2)\n\n\n\n\n\n\n\nImpotante\n\n\n\nPara que componentes principales tenga un alto rendimiento la información sdebe estar normalizada por Z-SCORE (StandardScaler)\n\\[ Z = \\frac{x - \\mu}{\\sigma} \\]\n\n\n\nPara calcular la componente principal, separamos nuestra base de datos con el fin de tener las dimensiones que contruyen el índice.\n\n\n### Hacemos un copia por si necesitamos un proceso con la base original\nPCA_COLONIAS = COLONIA_PCA.copy()\n\n### Seleccion de las dimensiones con las que se calcula el indice de desventajas \"PSINDER; PROM_OCUP; P3YM_HLI; P_15A24_M\"\n\nPCA_X = PCA_COLONIAS.drop(['CVE_COL','POBTOT'], axis = 1)\nPCA_y = PCA_COLONIAS[['CVE_COL']]\n\n\nSe normaliza la informacion por Z-Score, determinamos el número de componentes y aplicamos la función para calcular\n\n\n### Se normaliza la informacion por Z-Score\n\nS_TRANSF = StandardScaler()\nPCA_X_SCALER = pd.DataFrame(S_TRANSF.fit_transform(PCA_X), \n                            columns = PCA_X.columns)\n\n### Se determina el número de componentes\nPCA_N = PCA(n_components = 1)\nPCA_COMPONENTE = PCA_N.fit_transform(PCA_X_SCALER)\n\n\nSe calcula la varianza total por respecto al numero de componentes\n\n\n### Se calcula la varianza total por respecto al numero de componentes\nVARIANZA_TOTA = PCA_N.explained_variance_ratio_.sum() * 100\nprint(\"\\n Total de la variancia explicada \\n\", round(VARIANZA_TOTA,3), \"%\")\n\n\nCon una componente (PC1) se explica 66.82 % de la varianza total, lo cual implica que mas de la mitad de la información e los datos puede encapsularse en ese componente principal.\n\n\nfinalmente se indexan los resultados a la base de datos como una nueva columna con clave DIS_COL = concentrated disadvantage component\n\n\n### Pegamos los valores de PCA en la base de datos\nPCA_COLONIAS['DIS_COL'] = PCA_COMPONENTE\nPCA_COLONIAS.head(5)\n\n\n\n\n\n\n\nImpotante\n\n\n\nLo anterior lo transformamos a una funcion para optimizar el proceso de trabajo. Funcion que podemos llamar despues\n\n\n\ndef CONC_DIS (TABLA, DIM_CLAVE, DIM_POBLA):\n    \n    PCA_TABLA = TABLA.copy()\n    \n    ### Seleccion de las dimensiones con las que se calcula el indice de desventajas \"PSINDER; PROM_OCUP; P3YM_HLI; P_15A24_M\"\n     \n    PCA_X = PCA_TABLA.drop([DIM_CLAVE, DIM_POBLA], axis = 1)\n    PCA_y = PCA_TABLA[[DIM_CLAVE]]\n    \n    ### Se normaliza la informacion por Z-Score\n    \n    S_TRANSF = StandardScaler()\n    PCA_X_SCALER = pd.DataFrame( S_TRANSF.fit_transform(PCA_X), \n                                 columns = PCA_X.columns)\n                                 \n    ### Se determina el número de componentes\n    \n    PCA_N = PCA(n_components = 1)\n    PCA_COMPONENTE = PCA_N.fit_transform(PCA_X_SCALER)\n    \n    ### Se calcula la varianza total por respecto al numero de componentes\n     \n    VARIANZA_TOTA = PCA_N.explained_variance_ratio_.sum() * 100\n\n    print(\"\\n Total de la variancia explicada \\n\", round(VARIANZA_TOTA,3), \"%\")\n    ### Se indexan los resultados a la base de datos como una nueva columna con clave DIS_COL = concentrated disadvantage component \n    \n    PCA_TABLA['DISAD'] = PCA_COMPONENTE\n\n    PCA_TABLA = PCA_TABLA[[DIM_CLAVE, 'DISAD' ]]\n\n    return (PCA_TABLA)\n\n\nPodemos usar la función creada y aplicarla en los datos para revalidar los resultados.\n\n\n### Revalidación de información\n\nDESVE_COL = CONC_DIS (COLONIA_PCA, 'CVE_COL','POBTOT')\nDESVE_COL.head(2)\n\n\n\n4.1.3 Nivel Alcaldias\n\nEl Agrupamiento de datos por nivel Alcaldia para “PCA”. Recordando que la clave de Alcaldia == Municipio la podemos observar de la forma: DATA_FIN_USE.NOM_MUN.value_counts()\n\n\nALCALDIA_PCA = pd.DataFrame(DATA_FIN_USE.groupby(['MUN']).agg({'POBTOT': 'sum', \n                                                                  'PSINDER':'sum',\n                                                                  'PROM_OCUP': 'mean',\n                                                                  'P3YM_HLI':'sum',\n                                                                  'P_15A24_M': 'sum'}).reset_index())\nALCALDIA_PCA.head(2)\n\n\nAplicamos la funcion creada con anterioridad\n\n\n### Aplicando la función creada arriba\n\nDESVE_ALCA = CONC_DIS (ALCALDIA_PCA, 'MUN','POBTOT')\nDESVE_ALCA.head(2)\n\n\nEn este punto, podemos unir toda la información a la tabla original y renombramos las columnas de desventajas en cada nivel\n\n\nMERGE_DESVENTAJAS = DATA_FIN_USE.merge(DESVE_COL, \n                                       left_on = 'CVE_COL', \n                                       right_on = 'CVE_COL', \n                                       how = 'inner').merge(DESVE_ALCA, \n                                                            left_on ='MUN', \n                                                            right_on = 'MUN' , \n                                                            how = 'inner').rename({\"DISAD_x\": \"DIS_COL\", \"DISAD_y\": \"DIS_MUN\"}, axis = 1)\n\nMERGE_DESVENTAJAS.head(2)\n\n\nHacemos un mapita nuevamente\n\n\nfig, ax = plt.subplots(figsize=(8, 8))\nax = MERGE_DESVENTAJAS.plot(ax = ax, column='DIS_COL',\n                            legend= True,\n                            alpha=0.8,\n                            scheme='NaturalBreaks',\n                            cmap='copper',\n                            classification_kwds={'k':6})\nax.set(title='Desventajas a nivel Colonia, Ciudad de México')\n\nax.set_axis_off()\n\nplt.show()\n\n\nfig, ax = plt.subplots(figsize=(8, 8))\nax = MERGE_DESVENTAJAS.plot(ax = ax, column='DIS_MUN',\n                            legend= True,\n                            alpha=0.8,\n                            scheme='NaturalBreaks',\n                            cmap='copper',\n                            classification_kwds={'k':6})\nax.set(title='Desventajas a nivel Alcaldias, Ciudad de México')\n\nax.set_axis_off()\n\nplt.show()"
  },
  {
    "objectID": "data.html#el-jardín-de-las-bifurcaciones",
    "href": "data.html#el-jardín-de-las-bifurcaciones",
    "title": "2  Data Acquisition and Preprocessing",
    "section": "5.1 El jardín de las bifurcaciones",
    "text": "5.1 El jardín de las bifurcaciones\n\nEn esta seccion usaremos para calcular los valores de desorden social y fisico, usaremos dos formas: las claves de las manzanas y las coordenadas geograficas a fin de comparar resultados.\n\n\n5.1.1 Corrección columna clave de manzana\n\nInicialmente notamos de nuestra base de datos las columnas manzana, longitud y latitud. Para la primer bifurcación usaremos las claves de manzanas que se encuentran asignadas. Al hacer esto nos damos cuenta que necesitamos una limpieza de datos. Lo anterior por:\n\n\nEl tipo de dato es string esta en su forma es cientifico,\nTenemos que transformar los string a numeros aplicando la funcion “to_numeric”\nSe extiende el numero de su forma cientifica a su forma natural\nLos elementos con caracteres alfanumericos se asignan como “NAN”.\n\n\nEn este punto podemos notar que ya tenemos el string cientifico en “float”, lo que tenemos que hacer es extraer el numero sin notación cientifica, para eso aplicamos una funcion “lamnda” que convierta el float en string sin notación cientifica y los “nan_text” sean remplazamos por “NAN” verdaderos.\n\n\n\n\n\n\n\nImpotante\n\n\n\nRecordar que las claves comienzan con un cero y que el total de caracteres para manzanas son 16.\nCVEGEO = “0900700000000000”\n\n\n\n## Transformación de string to float \nManza_Num = pd.DataFrame(pd.to_numeric(All_Data_filtered['manzana'], errors = 'coerce'))\n\n## Se extiende el numero a su forma natural\nManza_Num = pd.DataFrame(Manza_Num['manzana'].apply(lambda x: '%.0f' %x)).replace('nan', np.nan)\n\n### Recordando que las claves comienzan con un cero y que para manzanas es un total de 16 caracteres\n### Asignamos el cero\n\nManza_Num['manzana'] = Manza_Num['manzana'].str.zfill(16)\n\nManza_Num.shape\n\n\nYa tenemos un dataframe con las claves en string y los indices como campo llave primaria con NAN verdaderos\n\n\nAhora vamos a hacer una union entre estos resultados y los el dataframe filtrado (All_Data_filtered) con base a su indice. Al ser un merge por indices, es recomendable que este este reiniciado (por lo que se entiende la necesidad de su reinicio en procesos anteriores).\n\n\nDe la union tendremos dos columnas con claves manzanas, las cuales las usaremos en una función para asignnación de clave corregida\n\n\n### Union entre tablas\nUSO_MANZAS = All_Data_filtered.merge(Manza_Num,\n                                     left_index = True,\n                                     right_index = True)\n\n\nLa asignacion de clave correcta: se lleva a cabo considerando las combianciones de resultados posibles entre las dos columnas de nombre manzanas (x,y). De lo anterior se obtienen las siguientes reglas de negocios:\n\n\nSi manzana_x == manzana_x & manzana_y == manzana_y, entonces el valor sera manzana_y\nSi manzana_x == manzana_x & manzana_y != manzana_y, entonces el valor sera manzana_x\nSi ninguno de los dos anteriores se cumple se asigna NAN\n\n\nCon base a las reglas se configura la función:\n\n\n### Creamos una función\ndef manzan_a(C):\n    if ((C.manzana_x == C.manzana_x) & (C.manzana_y == C.manzana_y)):\n        return C.manzana_y\n    elif ((C.manzana_x == C.manzana_x) & (C.manzana_y != C.manzana_y)):\n        return C.manzana_x\n    else:\n        return np.nan\n\n\nSe aplica la funcion y se eliminan las dimensiones no necesarias\n\n\n### Aplicamos la función\nUSO_MANZAS['CVEGEO'] = USO_MANZAS.apply(manzan_a, axis = 1)\n\n## Eliminamos las dimensiones no necesarias y tenemos la tabla de inicio\n\nUSO_MANZAS = USO_MANZAS.drop(['manzana_x', 'manzana_y'], axis = 1)\n\n\n\n5.1.2 Caso por Mananzas y Manzanas\n\nPara este caso, vamos a contar cuantos eventos de una determinada clase en el tipo de incidentes estan inmersos en las manzanas. Para la forma con columna y claves manzanas, seleccionamos unicamente las columnas de trabajo, en este caso se eliminan longitud y latitud.\n\n\nPara contabilizar las clases en la columna haremos uso de un dataframe dummy\n\n\n### Se eliminan columnas no necesarias\n\nUSO_MANZAS_TRUE = USO_MANZAS.drop(['latitud','longitud'], axis = 1)\n\n### Para contabilizar, notamos que la descripcion del incidente esta en fila,\n### por lo que tenemos que crear un dataframe dummy\n\nUSO_MANZAS_TRUE_DMY = pd.get_dummies(USO_MANZAS_TRUE, \n                                     columns=[\"Incidente\"], \n                                     prefix=[\"DM\"])\n\n\nAhora que tenemos nuestro dataframe dummy podemos contar, para lograr eso, tenemos que agrupar y sumar los eventos\n\n\n### Agrupación de dataframe Dummy\n\nMANZANA_DUMMMY = pd.DataFrame(USO_MANZAS_TRUE_DMY.groupby(['CVEGEO']).agg({'DM_AGUA_N': 'sum', \n                                                                           'DM_AGUA_P': 'sum',\n                                                                           'DM_BASURA_P': 'sum',\n                                                                           'DM_CORTO_ELE': 'sum',\n                                                                           'DM_DROGADO': 'sum',\n                                                                           'DM_EBRIO': 'sum',\n                                                                           'DM_ESCANDALO': 'sum',\n                                                                           'DM_FIESTA': 'sum',\n                                                                           'DM_FUGAS_N': 'sum',\n                                                                           'DM_GRAFITI': 'sum',\n                                                                           'DM_PERSO_R': 'sum',\n                                                                           'DM_VEHICULO': 'sum'\n                                                                          }).reset_index())\n\n\nAhora haremos oitra union y seleccionaremos aquellos elementos para crear el Desorden Social y fisico. Se unen la tabla DATA_FIN_USE y MANZANA_DUMMMY. Esto se hace en esa tabla porque debemos recordar que las manzanas tienen su asignacion de clave de colonias y alcaldias con base al criterio de maxima área.\n\n\n### Union de tablas \nSOCIAL_FISICO = DATA_FIN_USE.merge(MANZANA_DUMMMY,\n                                   left_on = 'CVEGEO',\n                                   right_on = 'CVEGEO',\n                                   how = 'left')"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "4  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  }
]