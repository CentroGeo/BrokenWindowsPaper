---
title: "Untitled"
format: html
---

### Concentración de desventajas

Construido a partir de cuatro dimensiónes (con base a censo 2010) y reducidad a una componente principal por PCA. Las dimensiones que se exponen en el articulo son:
- Porcentaje de masculinos de 15 a 29
- Porcentaje de población sin servicios a salud
- Promedio de habitantes que ocupan un hogar privado
- Porcentaje de personas que hablan una lengua indigena

Con base al Censo de población de 2020, las dimensiones se resumen de la forma:

### Concentración de desventajas

## Librerias 

import pandas as pd
import numpy as np
import geopandas as gpd
import contextily as ctx
from tabulate import tabulate
import matplotlib.pyplot as plt
from IPython.display import Markdown
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler



import warnings
warnings.filterwarnings('ignore')


table = [["P_15A17_M","Población masculina de 15 a 17 años"],
         ["P_18A24_M","Población masculina de 18 a 24 años"],
         ["PSINDER","Población sin afiliación a servicios de salud"],
         ["PROM_OCUP",'Promedio de ocupantes en viviendas particulares habitadas'],
         ["P3YM_HLI", "Población de 3 años y más que habla alguna lengua indígena"]]
Markdown(tabulate(
  table, 
  headers=["Clave","Descripción"]
))

print(tabulate(table, headers=["Clave","Descripción"], tablefmt='fancy_grid'))

La primer parte consta de cargar la base de datos de censo, seleccionar las dimensiones, limpiar la información y preparala para poder hacerla únion de estas en la geometry de la unidd geografica manzanas

#Entradas = 'D:/Users/LAAR8976/Desktop/MARC_SEPTEIMBRE/Entradas/'

CENSO_2020 =  pd.read_csv('MANZANAS.csv', encoding = 'Latin-1')
CENSO_2020 = CENSO_2020 [['ENTIDAD','NOM_ENT','MUN',
                          'NOM_MUN','LOC','NOM_LOC',
                          'AGEB','MZA','POBTOT', 
                          'P_15A17_M','P_18A24_M','PSINDER',
                          'PROM_OCUP', 'P3YM_HLI']]


CENSO_2020.shape

#### Filtramos eliminando las filas que contienen los totales 

Values = ['Total de la entidad','Total del municipio',
         'Total de la localidad urbana', 'Total AGEB urbana']
CENSO_2020_USE = CENSO_2020.query("NOM_LOC != @Values")
CENSO_2020_USE.shape


### Existe la presencia de filas donde los valores no estan presentes por lo que se hace necesario
### Remplazar los caracteres especiales o simbolos por "NAN"


CENSO_2020_USE = CENSO_2020_USE.replace({'999999999': np.nan, 
                                         '99999999': np.nan,
                                         '*': np.nan,
                                         'N/D': np.nan})
                  
DIM_NUM = CENSO_2020_USE.iloc[: , -6:].columns.tolist()
DIM_TEXT = CENSO_2020_USE.iloc[:, :8].columns.tolist()

CENSO_2020_USE[DIM_NUM] = CENSO_2020_USE[DIM_NUM].astype('float')
CENSO_2020_USE[DIM_TEXT] = CENSO_2020_USE[DIM_TEXT].astype(str)

CENSO_2020_USE.shape

Importante: se hace notar que las claves estan incompletas por lo que se agregan los "00" necesarios 

CENSO_2020_USE['ENTIDAD'] = CENSO_2020_USE['ENTIDAD'].str.zfill(2)
CENSO_2020_USE['MUN'] = CENSO_2020_USE['MUN'].str.zfill(3)
CENSO_2020_USE['LOC'] = CENSO_2020_USE['LOC'].str.zfill(4)
CENSO_2020_USE['AGEB'] = CENSO_2020_USE['AGEB'].str.zfill(4)  
CENSO_2020_USE['MZA'] = CENSO_2020_USE['MZA'].str.zfill(3)

CENSO_2020_USE['CVEGEO'] = CENSO_2020_USE[['ENTIDAD', 'MUN',
                                           'LOC','AGEB','MZA']].agg(''.join, axis=1)

CENSO_2020_USE['P_15A24_M'] = CENSO_2020_USE[["P_15A17_M", "P_18A24_M"]].sum(axis=1, min_count=1)

CENSO_2020_USE = CENSO_2020_USE.drop(['P_15A17_M','P_18A24_M'], axis = 1)

CENSO_2020_USE.shape

Se carga la base de datos geoespacial que corresponde a la unidad geografica de "manzanas".El archivo se encuentra en formato "json"


### Se carga el archivo espacial de Manzanas

MANZA_CDMX = gpd.read_file('MANZA_CDMX.json')
MANZA_CDMX = MANZA_CDMX[['CVEGEO','geometry']]
MANZA_CDMX.crs

### Merge en unidades Geoespaciales + Censo 2020
### Hasta esta parte lo que se ha hecho ha sido unir la informacion del censo con la unidad geoespacial
### El siguiente paso es llevar esto al siguiente nivel que es Manzanas --> A colonias 
### Colonias a Alcaldias 

MERGE = MANZA_CDMX.merge( CENSO_2020_USE,
                          left_on = 'CVEGEO',
                          right_on = 'CVEGEO',
                          how = 'inner')
MERGE.shape


fig, ax = plt.subplots(figsize=(5, 5))
ax = MERGE.plot(ax=ax, column='POBTOT',
                                            legend=False,
                                            alpha=0.8,
                                            scheme='NaturalBreaks',
                                            cmap='inferno',
                                            classification_kwds={'k':6})
ax.set(title='Población Total, Ciudad de México')

ax.set_axis_off()
#ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron, crs=MERGE.crs.to_string())



Hasta el punto anterior ya tenemos la información contenida dentro de las manzanas, el paso que sigue es llevar las manzanas a colonias
Para esto es necesario entender que ambos elementos son poligonales y que los centroides de manzanas no necesariamente refieren a la solucion contenida dentro de un poligono mayor.

Lo anterior se entiende cuando entendemos la forma de la geometria de un manzana la cual no es uniforme y el centroide puede estar (de forma radical) en extremos 

Por eso es necesario jugar con geometrias polygonales y con base al criterio de maxima área

Recordar que para área es necesario los crs en metros [to_crs(6372)]


### MANZANAS A COLONIAS 


> Validar crs se encuentre en metros "6362 o 6362" , en caso contrario es necesrio llevar a cabo una reproyección 

COLONIAS_CDMX = gpd.read_file('new_colo.json')
print("Colonias CRS", COLONIAS_CDMX.crs)
print("Manzanas CRS", MERGE.crs)

MANZANA_METROS = MERGE.to_crs(6362)
COLONIAS_METROS = COLONIAS_CDMX.to_crs(6362)

print("Crs Manzanas", MANZANA_METROS.crs )
print("Crs Colonias", COLONIAS_METROS.crs )


### Se busca identificar la intersección de elementos con base al criterio de área

INTERSECCION = gpd.overlay(COLONIAS_METROS,
                           MANZANA_METROS,
                            how = 'intersection')


### Se calcula el valor de área para cada poligono intersectado

INTERSECCION['area'] = INTERSECCION.geometry.area 

### Para cada overlay se ordena el área de manera descendente y se eliminan los duplicados con base base a una columna y de esa se mantiene 
### unicamente el primer valor 

INTERSECCION = (INTERSECCION.sort_values('area', ascending = False).
                drop_duplicates(subset="CVEGEO", keep = 'first').
                drop(['geometry','area'], axis = 1))


INTERSECCION_USE = INTERSECCION.drop(['ENT', 'CVEDT', 'NOMDT', 'DTTOLOC'], axis = 1)

#### Remplazo caracteres especiales

Dic_Ca = {'Ã‘': 'Ñ'}

INTERSECCION_USE.replace(Dic_Ca, inplace=True, regex=True)
INTERSECCION_USE.columns = INTERSECCION_USE.columns.to_series().replace(Dic_Ca, regex=True)


INTERSECCION_USE.shape


### Se une la información de overly de las Manzanas ya alineadas con colonias en la geometry de las manzanas para tener la base final 
### La base final debe tener la información a nivel:
### ---> Manzana
### ---> Colonia
### ---> Alcaldia

DATA_FINAL_USE = MANZA_CDMX.merge(INTERSECCION_USE,
                          left_on = 'CVEGEO',
                          right_on = 'CVEGEO',
                          how = 'inner').rename({"CVEUT": "CVE_COL", "NOMUT": "NOM_COL", "ID": "ID_COL"}, axis = 1)
DATA_FINAL_USE.shape

> Se valida que cada manzana este asociada a cada una de las colonias  
Recorndado que la relación es una colonia a muchas manzanzanas  
"" Por lo que no deben existir manzanas repetididas"

$$M_{n-1} = f(C)$$
$$ C \gets M_{n-1}$$

### Se valida que no existan manzanas repetidas

DATA_FINAL_USE.CVEGEO.value_counts()

### Recordando que la relacion es muchas manzanas a una colonia, los valores de tantas veces repetida una colonia
### Son relacion de tantas veces se repite la colonia por las n manzanas 

DATA_FINAL_USE.CVE_COL.value_counts()

### Aqui validamos como las claves de las manzanas son diferentes para una misma colonia
### Se entiende la relacion, muchas manzanas a una colonia

DATA_FINAL_USE.query('CVE_COL == "07-320"').head(3)

* Reordenamos la información de la forma "Regional a local" es decir:

$$ Alcaldia \to Colonia \to Manzana $$

1. **Alcaldia**: _ENTIDAD, NOM_ENT, MUN, NOM_MUN, LOC, NOM_LOC,_  
2. **Colonia**: _ID_COL, CVE_COL, NOM_COL,_ 
3. **Manzana**: _AGEB, MZA, CVEGEO,_
3. **Dimensiones**: _POBTOT, PSINDER, PROM_OCUP, P3YM_HLI, P_15A24_M_
4. **Geometry**

### Reordenamiento de la información

DATA_FIN_USE = DATA_FINAL_USE[['ENTIDAD','NOM_ENT', 'MUN', 'NOM_MUN', 'LOC', 'NOM_LOC',
                               'ID_COL','CVE_COL', 'NOM_COL', 'AGEB', 'MZA',
                               'POBTOT', 'PSINDER', 'PROM_OCUP', 'P3YM_HLI', 'P_15A24_M',
                               'geometry']]

DATA_FIN_USE.head(1)

### Un mapita porque nos gustan los mapitas 

DATA_FIN_USE.plot('POBTOT', legend=False,
                   alpha=0.8,
                   scheme='NaturalBreaks',
                   cmap='inferno',
                   classification_kwds={'k':6})

### Análisis de Componentes Principales (PCA)

En esta sección se cálcula el indice de **_Concetración de desventajas_** mediante la reducción de las dimensiónes por componentes principales

Esto se hace a nivel **Alcaldias y Delegaciones**

> Comenzamos agrupando la información y calculando los nuevos valores


##### Nivel Colonia

### Agrupamiento de datos por nivel colonia para "PCA"

COLONIA_PCA = pd.DataFrame(DATA_FIN_USE.groupby(['CVE_COL']).agg({'POBTOT': 'sum', 
                                                                  'PSINDER':'sum',
                                                                  'PROM_OCUP': 'mean',
                                                                  'P3YM_HLI':'sum',
                                                                  'P_15A24_M': 'sum'}).reset_index())
COLONIA_PCA.head(2)

La información se encuentra normalizada por **Z-SCORE (StandardScaler)**

$$ Z = \frac{x - \mu}{\sigma} $$


PCA_COLONIAS = COLONIA_PCA.copy()

### Seleccion de las dimensiones con las que se calcula el indice de desventajas "PSINDER; PROM_OCUP; P3YM_HLI; P_15A24_M"

PCA_X = PCA_COLONIAS.drop(['CVE_COL','POBTOT'], axis = 1)
PCA_y = PCA_COLONIAS[['CVE_COL']]

### Se normaliza la informacion por Z-Score

S_TRANSF = StandardScaler()
PCA_X_SCALER = pd.DataFrame(S_TRANSF.fit_transform(PCA_X), 
                            columns = PCA_X.columns)

### Se determina el número de componentes
PCA_N = PCA(n_components = 1)
PCA_COMPONENTE = PCA_N.fit_transform(PCA_X_SCALER)

### Se calcula la varianza total por respecto al numero de componentes
VARIANZA_TOTA = PCA_N.explained_variance_ratio_.sum() * 100
print("\n Total de la variancia explicada \n", round(VARIANZA_TOTA,3), "%")
### Se indexan los resultados a la base de datos como una nueva columna con clave DIS_COL = concentrated disadvantage component 
PCA_COLONIAS['DIS_COL'] = PCA_COMPONENTE

PCA_COLONIAS.head(5)

#### Lo anterior lo transformamos a una funcion para optimizar el proceso de trabajo
#### Funcion que podemos llamar despues 

def CONC_DIS (TABLA, DIM_CLAVE, DIM_POBLA):
    
    PCA_TABLA = TABLA.copy()
    
    ### Seleccion de las dimensiones con las que se calcula el indice de desventajas "PSINDER; PROM_OCUP; P3YM_HLI; P_15A24_M"
     
    PCA_X = PCA_TABLA.drop([DIM_CLAVE, DIM_POBLA], axis = 1)
    PCA_y = PCA_TABLA[[DIM_CLAVE]]
    
    ### Se normaliza la informacion por Z-Score
    
    S_TRANSF = StandardScaler()
    PCA_X_SCALER = pd.DataFrame( S_TRANSF.fit_transform(PCA_X), 
                                 columns = PCA_X.columns)
                                 
    ### Se determina el número de componentes
    
    PCA_N = PCA(n_components = 1)
    PCA_COMPONENTE = PCA_N.fit_transform(PCA_X_SCALER)
    
    ### Se calcula la varianza total por respecto al numero de componentes
     
    VARIANZA_TOTA = PCA_N.explained_variance_ratio_.sum() * 100

    print("\n Total de la variancia explicada \n", round(VARIANZA_TOTA,3), "%")
    ### Se indexan los resultados a la base de datos como una nueva columna con clave DIS_COL = concentrated disadvantage component 
    
    PCA_TABLA['DISAD'] = PCA_COMPONENTE

    PCA_TABLA = PCA_TABLA[[DIM_CLAVE, 'DISAD' ]]

    return (PCA_TABLA)

### Aplicamos la función para validacion

DESVE_COL = CONC_DIS (COLONIA_PCA, 'CVE_COL','POBTOT')
DESVE_COL.head(2)

### Agrupamiento de datos por nivel Alcaldia para "PCA"

### Recordando que la clave de Alcaldia == Municipio la podemos observar de la forma: DATA_FIN_USE.NOM_MUN.value_counts()

ALCALDIA_PCA = pd.DataFrame(DATA_FIN_USE.groupby(['MUN']).agg({'POBTOT': 'sum', 
                                                                  'PSINDER':'sum',
                                                                  'PROM_OCUP': 'mean',
                                                                  'P3YM_HLI':'sum',
                                                                  'P_15A24_M': 'sum'}).reset_index())
ALCALDIA_PCA.head(2)

#### Aplicamos la funcion creada con anterioridad

DESVE_ALCA = CONC_DIS (ALCALDIA_PCA, 'MUN','POBTOT')
DESVE_ALCA.head(2)

#### Unimos toda la información a la tabla original y renombramos las columnas de desventajas en cada nivel

MERGE_DESVENTAJAS = DATA_FIN_USE.merge(DESVE_COL, 
                                       left_on = 'CVE_COL', 
                                       right_on = 'CVE_COL', 
                                       how = 'inner').merge(DESVE_ALCA, 
                                                            left_on ='MUN', 
                                                            right_on = 'MUN' , 
                                                            how = 'inner').rename({"DISAD_x": "DIS_COL", "DISAD_y": "DIS_MUN"}, axis = 1)

MERGE_DESVENTAJAS.head(2)

### CASO 02
* LLAMADAS 311 (PUNTOS) a MANZANAS
* MANZANAS a COLONIAS

Para el caso donde se usan geometrias puntuales de las llamadas 911 para llevar los de puntos a manzanas usamos sjoins contains, lo que buscamos es que los puntos queden dentro de un poligono


La secuencia es la misma....

1. Vemos cuantos puntos estan dentro de las manzanas
2. Como las manzanas ya tienen informacion entendemos ahora eso como un poligono 
3. En esta seccion tenemos dos rutas:
  3.1 Se hace la seccion de INTERSECCION = gpd.overlay para saber que manzanas estan dentro de los poligonos y se continua on el proceso que hemos hecho
  3.2 Como ya sabemos que manzanas pertenence a que claves, unicamente hacemos un Merge de las cuentas de las manzanas con lo que ya tenemos en la linea donde llamamos al Frame "DATA_FIN_USE"
4. Calculamos a nivel colonia y alcaldia por PCA los indices





### Como nos gustan los mapitas
# Hacemos un mapita pa ver como se distribuyen 

### Llamadas sin clasificar en las manzanas de la cdmx 

#base = Manzanas.plot(color='black',figsize=(10,10))
#Llamadas_911.plot(ax=base, color='red', markersize = 5, figsize=(10,10))

### Puntos dentro de poligonos 

#Manza_911 = gpd.sjoin( Manzanas, 
 #                     Llamadas_911[['folio', 'geometry']], 
  #                    how="right", 
   #                   op='contains')


#### Una vez dentro los puntos necesitamos contar o sumar (¿?) con base a la clave


#Muestra  = Manza_911[['clave_cvgeo', 'folio']]

#Muestra = (Muestra.groupby('clave_cvgeo').count()).rename(columns={"folio": "Value"}).replace(np.nan, 0)



#### Ya tenemos el conteo , suma, etc para cada manzana, ahora lo que necesitamos es pegar esa info en las manzanas

### Manzanas_llamadas = Manzanas.merge(Muestra, 
#                                      left_on = 'CVEGEO',
                          #            right_on = 'CVEGEO',
                        #              how = 'inner')


#### A PARTIR DE ESTE PUNTO SE BIFURCA A 3.1 O 3.2
###  EEN ESTE PUNTO YA SABEMOS CUANTOS ELEMENTOS TENEMOS EN CADA MANZANA POR LO QUE SE ELEIGE QUE HACER



https://dreampuf.github.io/GraphvizOnline/#digraph%20g%20%7B%0D%0Arankdir%20%3D%20LR%0D%0Anode%20%5Bmargin%20%3D%200.2%20fontcolor%20%3D%20white%20fontsize%20%3D%2012%20width%3D1%20style%20%3D%20filled%5D%0D%0A%0D%0AIC_EMPLEADOS%20-%3E%20MERGE%3B%0D%0AIRV_PREVE%20-%3E%20MERGE%3B%0D%0AEXP_EMPLEADO%20-%3E%20MERGE%3B%0D%0AMERGE%20-%3E%20INTEGRA_RIESGOS_EMP%3B%0D%0A%0D%0AIC_EMPLEADOS%20%5Bcolor%20%3D%20%22%23006666%22%2C%20shape%20%3D%20%22note%22%5D%3B%0D%0AIRV_PREVE%20%5Bcolor%20%3D%20%22%23006666%22%2C%20shape%20%3D%20%22note%22%5D%3B%0D%0AEXP_EMPLEADO%20%5Bcolor%20%3D%20%22%23006666%22%2C%20shape%20%3D%20%22note%22%5D%3B%0D%0AMERGE%20%5Bcolor%20%3D%20%22black%22%2C%20shape%20%3D%20%22box3d%22%2C%20label%3D%22Key%3A%20Empleado%22%5D%3B%0D%0AINTEGRA_RIESGOS_EMP%5Bcolor%20%3D%20%22%239B2242%22%2C%20shape%20%3D%20%22component%22%5D%0D%0A%0D%0A%7D
