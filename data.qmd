---
title: "Data Acquisition and Preprocessing"
format: html
---

# Adquisition 

[Censo de poblacion 2020](https://www.inegi.org.mx/programas/ccpv/2020/default.html#Microdatos)

[Descarga masiva Manzanas](https://www.inegi.org.mx/app/descarga/?ti=13&ag=01)

[Llamadas del 911](https://datos.cdmx.gob.mx/dataset/llamadas-numero-de-atencion-a-emergencias-911)

# Índice de Concentración de desventajas

Construido a partir de cuatro dimensiónes (con base a censo 2010) y reducidad a una componente principal por PCA. Las dimensiones que se exponen en el articulo son:
- Porcentaje de masculinos de 15 a 29
- Porcentaje de población sin servicios a salud
- Promedio de habitantes que ocupan un hogar privado
- Porcentaje de personas que hablan una lengua indigena

Con base al Censo de población de 2020, las dimensiones se resumen de la forma:

```{python}
#| eval: true
#| echo: false
from tabulate import tabulate
from IPython.display import Markdown

table = [["P_15A17_M","Población masculina de 15 a 17 años"],
         ["P_18A24_M","Población masculina de 18 a 24 años"],
         ["PSINDER","Población sin afiliación a servicios de salud"],
         ["PROM_OCUP",'Promedio de ocupantes en viviendas particulares habitadas'],
         ["P3YM_HLI", "Población de 3 años y más que habla alguna lengua indígena"]]
Markdown(tabulate(
  table, 
  headers=["Clave","Descripción"]))
```

> > La primer parte consta de cargar la base de datos de censo, seleccionar las dimensiones, limpiar la información y preparala para poder hacerla únion de estas en la geometry de la unidd geografica manzanas. Se cargan las librerias necesarias.

```{python}
#| eval: true
#| echo: true
## Librerias 

import numpy as np
import pandas as pd
import geopandas as gpd
import contextily as ctx
import matplotlib.pyplot as plt
from IPython.display import Markdown
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

### Warnings
import warnings
warnings.filterwarnings('ignore')


```

> Se carga la información del Censo por unidad manzanas conservando unicamente los campos de interes: **ENTIDAD, NOM_ENT, MUN, NOM_MUN LOC, NOM_LOC, AGEB, MZA, POBTOT, P_15A17_M, P_18A24_M, PSINDER, PROM_OCUP y P3YM_HLI**

```{python}
#| echo: false
#| eval: true
Entradas = '/Users/ladino/Desktop/Doctorado_Clases/'

```

> De la base de datos filtramos eliminando las filas que contienen los totales 

```{python}
#| eval: true
CENSO_2020 =  pd.read_csv(Entradas + 'MANZANAS.csv', encoding = 'Latin-1')
CENSO_2020 = CENSO_2020 [['ENTIDAD','NOM_ENT','MUN',
                          'NOM_MUN','LOC','NOM_LOC',
                          'AGEB','MZA','POBTOT', 
                          'P_15A17_M','P_18A24_M','PSINDER',
                          'PROM_OCUP', 'P3YM_HLI']]

Values = ['Total de la entidad','Total del municipio',
         'Total de la localidad urbana', 'Total AGEB urbana']

CENSO_2020 = CENSO_2020.query("NOM_LOC != @Values")

CENSO_2020.head(2)                         
```


> Dentro de la base de datos existe la presencia de filas donde los valores son simbolos o caracteres especiales(*, N/D, 99999, etc), por lo que es necesario remplazarlos por valores NAN.

```{python}
#| eval: true
CENSO_2020 = CENSO_2020.replace({'999999999': np.nan, 
                                 '99999999': np.nan,
                                 '*': np.nan,
                                 'N/D': np.nan})
                  
DIM_NUM = CENSO_2020.iloc[: , -6:].columns.tolist()
DIM_TEXT = CENSO_2020.iloc[:, :8].columns.tolist()

CENSO_2020[DIM_NUM] = CENSO_2020[DIM_NUM].astype('float')
CENSO_2020[DIM_TEXT] = CENSO_2020[DIM_TEXT].astype(str)
```

> De igual manera la información referida a a las columnas de "Entidad, Municipio, Localidad, AGEB y Manzana", no presetan el formato necesario para crear la columna CVEGEO, por lo que debemos completar la información de la forma correcta.

> Creada la columna CVEGEO, calculamos la dimensión población masculina de 15 a 24 años como la suma de "P_15A17_M y P_18A24_M". Una vez que hemos creado la dimensión se hacen poco necesarias "P_15A17_M y P_18A24_M, por lo que se eliminan.


```{python}
#| eval: true
## Corrección de información
CENSO_2020['ENTIDAD'] = CENSO_2020['ENTIDAD'].str.zfill(2)
CENSO_2020['MUN'] = CENSO_2020['MUN'].str.zfill(3)
CENSO_2020['LOC'] = CENSO_2020['LOC'].str.zfill(4)
CENSO_2020['AGEB'] = CENSO_2020['AGEB'].str.zfill(4)  
CENSO_2020['MZA'] = CENSO_2020['MZA'].str.zfill(3)

CENSO_2020['CVEGEO'] = CENSO_2020[['ENTIDAD', 'MUN',
                                   'LOC','AGEB','MZA']].agg(''.join, axis=1)

## Cálculo de Población masculina de 15 a 24 años
CENSO_2020['P_15A24_M'] = CENSO_2020[["P_15A17_M", 
                                      "P_18A24_M"]].sum(axis = 1, 
                                                        min_count = 1)

## Eliminación de dimensiones
CENSO_2020 = CENSO_2020.drop(['P_15A17_M','P_18A24_M'], axis = 1)

CENSO_2020.head(2)
```


> Se carga la base de datos geoespacial que corresponde a la unidad geografica de "manzanas". Para este caso, el archivo se encuentra en formato "json". Del archivo, unicamente consideramos las columnas "CVEGEO y geometry"



```{python}
#| eval: true
### Se carga el archivo espacial de Manzanas

MANZA_CDMX = gpd.read_file(Entradas +'MANZA_CDMX.json')
MANZA_CDMX = MANZA_CDMX[['CVEGEO','geometry']]
MANZA_CDMX.head(2)
```

> Union (merge) de las unidades geoespaciales con la información del Censo de Población y vivienda 2020. En este punto a cada unidad geografica le asignamos la información del censo de población.


```{python}
#| eval: true

### Union a la izquierda con campo llave primaria "CVEGEO" #### Mantener Merge con cualquiera de los dos :)
MERGE = MANZA_CDMX.merge( CENSO_2020,
                          left_on = 'CVEGEO',
                          right_on = 'CVEGEO',
                          how = 'inner')
MERGE.head(2)          
```

> Siempre es importante saber en que sistema de proyección se encuentran nuestros datos, para eso usamos "crs"

```{python}
#| eval: true
MERGE.crs
```


> Hacemos un mapa de P_15A24_M para ver su distribución espacial.

```{python}
#| eval: true
fig, ax = plt.subplots(figsize=(8, 8))
ax = MERGE.plot(ax = ax, column='P_15A24_M',
                legend=False,
                alpha=0.8,
                scheme='NaturalBreaks',
                cmap='copper',
                classification_kwds={'k':6})
ax.set(title='Población Masculina 15 a 24 años, Ciudad de México')

ax.set_axis_off()

plt.show()

```


> Hasta el punto anterior tenemos la información contenida dentro de las manzanas, el paso que sigue es llevar las manzanas a colonias. Para esto es necesario entender que ambos elementos son poligonales y que los centroides de manzanas no necesariamente refieren a la solución contenida dentro de un poligono mayor.

> Por eso es necesario usar el criterio de maxima área de la sobreposición de poligonos. Al hablar de área el sistema de proyección debe estar en metros, por lo que si no lo esta se debe cambiar. Para este caso se cambio a [EPSG:6362](https://epsg.io/6362)

> Se cargan las colonias y se valida que ambos crs se encuentren en metros "6362 o 6362" , en caso contrario es necesrio llevar a cabo una reproyección.

```{python}
#| eval: true
COLONIAS_CDMX = gpd.read_file(Entradas +'COLONIAS.json').rename({ "CVEUT": "CVE_COL"}, axis = 1)
COLONIAS_CDMX['CVEDT'] = COLONIAS_CDMX['CVEDT'].str.zfill(3)

print("Colonias CRS", COLONIAS_CDMX.crs)
print("Manzanas CRS", MERGE.crs)
```

> Los archivos estan en coordenadas geograficas, por lo que se reproyecta

```{python}
#| eval: true
MERGE = MERGE.to_crs(6362)
COLONIAS_CDMX = COLONIAS_CDMX.to_crs(6362)

print("Crs Manzanas", MERGE.crs )
print("Crs Colonias", COLONIAS_CDMX.crs )
```


> Buscamos en este punto identificar la intersección entre colonias y manzanas para asignar a cada manzana (base al criterio de área maxima) la clave de la colonia a la que pertence.

```{python}
#| eval: true
INTERSECCION = gpd.overlay(COLONIAS_CDMX,
                           MERGE,
                           how = 'intersection')

```

> Se calcula el valor de área para cada poligono intersectado

```{python}
#| eval: true
## Se calcula el area 
INTERSECCION['area'] = INTERSECCION.geometry.area
```

> Para el overlay se reordena la información del área de manera descendente y se eliminan los duplicados con base a la "CVEGEO" manteniendo unicamente el primer valor

```{python}
#| eval: true
INTERSECCION = (INTERSECCION.sort_values('area', ascending = False).
                drop_duplicates(subset="CVEGEO", keep = 'first').
                drop(['geometry','area'], axis = 1))

### Se eliminan columnas no necesarias
INTERSECCION = INTERSECCION.drop(['ENT', 'CVEDT', 'NOMDT', 'DTTOLOC'], axis = 1) #### Se mantiene solo uno 

```

> En la base de colonias se identificaron caracteres especiales, por lo que se procede a remplazarlos, por su valor correspondiente.

```{python}
#| eval: true

Dic_Ca = {'Ã‘': 'Ñ'}
INTERSECCION.replace(Dic_Ca, inplace=True, regex=True)
INTERSECCION.columns = INTERSECCION.columns.to_series().replace(Dic_Ca, regex=True)

INTERSECCION.shape

```


> Se valida que cada manzana este asociada a cada una de las colonias  
Recorndado que la relación es una colonia a muchas manzanzanas  
"" Por lo que no deben existir manzanas repetididas"

$$M_{n-1} = f(C)$$
$$ C \gets M_{n-1}$$

> Se valida que no existan manzanas repetidas
```{python}
#| eval: false
INTERSECCION.CVEGEO.value_counts()
```

> La relacion de muchas manzanas a una colonia, se valida para cada clave de colonias se repite tantas veces existan manzanas

```{python}
#| eval: true
INTERSECCION.CVE_COL.value_counts()
```


> Aqui validamos como las claves de las manzanas son diferentes para una misma colonia y se entiende la relacion, muchas manzanas a una colonia

```{python}
#| eval: true
INTERSECCION.query('CVE_COL == "07-320"').head(3)
```



# Análisis de Componentes Principales (PCA)

>En esta sección se cálcula el indice de **_Concetración de desventajas_** mediante la reducción de las dimensiónes por componentes principales (PCA). Esto se hace a nivel **Alcaldias y Delegaciones**. La información a nivel alcaldia y delegacion es un proceso de reagrupacion y nuevos calculos de los valores.


::: {.callout-important icon=false}
## Impotante
Para que componentes principales tenga un alto rendimiento la información sdebe estar normalizada por **Z-SCORE (StandardScaler)**

$$ Z = \frac{x - \mu}{\sigma} $$
:::

> Para calcular la componente principal se ha creado una funcion que encapsula los siguientes procesos:
1. Seleccion de las dimensiones con las que se calcula el indice
2. Se normaliza la informacion por Z-Score
3. Se determina el número de componentes a reducir la información
4. Se calcula la varianza total por respecto al numero de componentes
5. Se indexan los resultados a la base de datos como una nueva columna con un nombre de clave


```{python}
#| eval: true

def CONC_DIS (TABLA, DIM_CLAVE, PCA_NAME):
    
    ### Seleccion de las dimensiones con las que se calcula el indice de desventajas "PSINDER; PROM_OCUP; P3YM_HLI; P_15A24_M"
     
    PCA_X = TABLA.drop([DIM_CLAVE], axis = 1)
    PCA_y = TABLA[[DIM_CLAVE]]
    
    ### Se normaliza la informacion por Z-Score
    
    S_TRANSF = StandardScaler()
    PCA_X_SCALER = pd.DataFrame( S_TRANSF.fit_transform(PCA_X), 
                                 columns = PCA_X.columns)
                                 
    ### Se determina el número de componentes
    
    PCA_N = PCA(n_components = 1)
    PCA_COMPONENTE = PCA_N.fit_transform(PCA_X_SCALER)
    
    ### Se calcula la varianza total por respecto al numero de componentes
     
    VARIANZA_TOTA = PCA_N.explained_variance_ratio_.sum() * 100

    print("\n Total de la variancia explicada por la componente \n", round(VARIANZA_TOTA,3), "%")
    
    ### Se indexan los resultados a la base de datos como una nueva columna con clave DIS_COL = concentrated disadvantage component 
    
    TABLA[PCA_NAME] = PCA_COMPONENTE

    TABLA = TABLA[[DIM_CLAVE, PCA_NAME]]

    return (TABLA)

```

### Nivel Colonias

> Para este punto agrupamos los datos por nivel colonia para extraer el valor del índice por "PCA"

```{python}
#| eval: true
COLONIA_PCA = pd.DataFrame(INTERSECCION.groupby(['CVE_COL']).agg({'PSINDER':'sum',
                                                                  'PROM_OCUP': 'mean',
                                                                  'P3YM_HLI':'sum',
                                                                  'P_15A24_M': 'sum'}).reset_index())
COLONIA_PCA.head(2)
```


> Usamos la función creada en los datos para obtener los resultados.

```{python}
#| eval: true

### Revalidación de información
DESVE_COL = CONC_DIS (COLONIA_PCA, 'CVE_COL', 'DIS_COL')
DESVE_COL.head(2)
```

### Nivel Alcaldias

> El Agrupamiento de datos por nivel Alcaldia para "PCA". Recordando que la clave de Alcaldia == Municipio la podemos observar de la forma: DATA_FIN_USE.NOM_MUN.value_counts()

```{python}
#| eval: true
ALCALDIA_PCA = pd.DataFrame(INTERSECCION.groupby(['MUN']).agg({'PSINDER':'sum',
                                                               'PROM_OCUP': 'mean',
                                                               'P3YM_HLI':'sum',
                                                               'P_15A24_M': 'sum'}).reset_index())
ALCALDIA_PCA.head(2)
```

> Aplicamos la funcion creada para obtener los resultados a nivel alcaldia

```{python}
#| eval: true
### Aplicando la función creada arriba

DESVE_ALCA = CONC_DIS (ALCALDIA_PCA, 'MUN','DIS_MUN')
DESVE_ALCA.head(2)
```


# Índice del Desorden Social y Físico

> En esta seccion se usaran las llamadas del 911 para crear los índices de desorden social y desorden fisico comprendidas en dos semestres, para este caso se han usado las llamadas del primer y segundo semestre del 2021.

> Las dimensiones que se han de usar son las siguientes

```{python}
#| eval: true
#| echo: false
#| tbl-cap: Desorden Social
table = [["Intoxicación pública con drogas",
         "Administrativas-Drogados"],
         ["Intoxicación pública con alcohol","Administrativas-Ebrios",],
         ["Incidencia pública","NA"],
         ["Orinar en público","NA"],
         ["Denuncia de persona en riesgo", "Denuncia-Persona en Riesgo"],
         ["Disturbios públicos escándalo callejero", "Disturbio-Escándalo"],
         ["Disturbios públicos fiestas ruidosas", "Disturbio-Escándalo"],
         ["Tirar basura", "Administrativas-Tirar Basura en Vía Pública"]]
Markdown(tabulate(
  table, 
  headers=["Clave","Descripción"]))
```


```{python}
#| eval: true
#| echo: false
#| tbl-cap: Desorden Físico
table = [["Vehículo abandonado con placas", "Abandono-Vehículo" ],
         ["Graffiti", "Administrativas-Grafitis"],
         ["Fuga de agua potable","Derrame o Fuga-Agua Potable"],
         ["Derrame de aguas residuales", "Derrame o Fuga-Aguas Negras"],
         ["Líneas eléctricas caídas", "Servicios-Corto Circuito instalación o subestación eléctrica"],
         ["Fugas de gas", "Derrame o Fuga-Gas Natural"]]
Markdown(tabulate(
  table, 
  headers=["Clave","Descripción"]))
```


> Se cargan las bases de datos correspondientes a los semestres del añp 2021 y se concatenan a un solo dataframe para tener todos los meses

```{python}
#| eval: true
### Llamadas del 911 
LL_911_s1 =  pd.read_csv(Entradas + 'llamadas_911_2021_s1.csv', encoding = 'Latin-1')
LL_911_s2 =  pd.read_csv(Entradas + 'llamadas_911_2021_s2.csv', encoding = 'Latin-1')

### Concatenaciones de semestres
Frame_C = [LL_911_s1, LL_911_s2]
All_Data = pd.concat(Frame_C)
```

> Validamos que se encuentren los doce meses en la columna "mes_cierre". En este punto surgen dudas, ¿se eliminan los folios repetidos o se mantienen?

```{python}
#| eval: true
### Validación de meses
All_Data.mes_cierre.value_counts()
```

> Con la validación de la información, seleccionamos unicamente de la dimension "incidente_c4" las clases con las que trabajaremos. De igual manera, se simplifica la descripción de las clases, se resetea el index para comenzar desde cero, seleccionamos unicamente las dimensiones que usaremos para los demas procesos (folio, categoria_incidente_c4, incidente_c4, manzana, latitud, longitud) y renombramos los campos necesarios.

```{python}
#| eval: true
#|
### Seleeción los valores de la dimension como una lista
Lista = ["Drogados", "Ebrios" , "Persona en riesgo", "Escandalo", "Fiestas" , "Tirar basura en via publica",
         "Vehiculo", "Grafitis", "Agua potable", "Aguas negras", "Corto circuito instalacion o subestacion electrica", "Fuga de gas natural"]

All_Data = All_Data[All_Data['incidente_c4'].isin(Lista)]

All_Data = All_Data.replace({'Fiestas':'FIESTA','Escandalo':'ESCANDALO','Ebrios':'EBRIO',
                                              'Agua potable':'AGUA_P','Drogados':'DROGADO','Vehiculo':'VEHICULO',
                                              'Grafitis':'GRAFITI','Persona en riesgo':'PERSO_R',
                                              'Aguas negras':'AGUA_N', 'Tirar basura en via publica':'BASURA_P',
                                              'Corto circuito instalacion o subestacion electrica':'CORTO_ELE',
                                              'Fuga de gas natural':'FUGAS_N'}).reset_index(drop = True)

All_Data = All_Data[["folio","categoria_incidente_c4","incidente_c4", 
                     "manzana","latitud","longitud"]].rename({"categoria_incidente_c4": "Categoria",
                                                              "incidente_c4": "Incidente"}, axis = 1)

All_Data.head(2)                                                            


```


```{python}
#| eval: true
#|
All_Data = gpd.GeoDataFrame(All_Data,
                              geometry = gpd.points_from_xy(All_Data.longitud,
                                                            All_Data.latitud), crs=4326).drop(['latitud','longitud'], axis = 1).to_crs(6362)
All_Data.head(2)
```


```{python}
#| eval: true
#|
base = COLONIAS_CDMX.plot(color ='black',figsize=(5,5))
All_Data.plot(ax = base, color = 'red', markersize = 2, figsize=(5,5))
```



```{python}
#| eval: true
#|
CATEGORIAS = gpd.sjoin(COLONIAS_CDMX.drop(['ENT','NOMDT','NOMUT','DTTOLOC','ID'], axis = 1), 
                        All_Data[['Categoria','Incidente','geometry']], 
                         how = "inner", 
                         op = 'contains').drop(['geometry','index_right'], axis = 1)
CATEGORIAS.head(2)
```


```{python}
#| eval: true
#|
CATEGORIAS_DMY = pd.get_dummies(CATEGORIAS, 
                                columns=["Incidente"], 
                                prefix=["DM"]).rename({'CVEDT': 'MUN'}, axis = 1)

CATEGORIAS_DMY.head(3)
```

> **Ahora calculamos los indices**

```{python}
#| eval: true
#|

### Social a nivel colonia 

SOCIAL_COL = pd.DataFrame(CATEGORIAS_DMY.groupby(['CVE_COL']).agg({'DM_DROGADO': 'sum',
                                                                   'DM_EBRIO':'sum',
                                                                   'DM_ESCANDALO': 'sum',
                                                                   'DM_FIESTA':'sum',
                                                                   'DM_BASURA_P': 'sum',
                                                                   'DM_PERSO_R': 'sum'}).reset_index())

COLONIA_SOCIAL = CONC_DIS(SOCIAL_COL, 'CVE_COL', 'SOCIAL_COL')
COLONIA_SOCIAL.head(2)

```


```{python}
#| eval: true
#|

### Fisico a nivel colonia 

FISICO_COL = pd.DataFrame(CATEGORIAS_DMY.groupby(['CVE_COL']).agg({'DM_VEHICULO': 'sum',
                                                                'DM_GRAFITI':'sum',
                                                                'DM_AGUA_P': 'sum',
                                                                'DM_AGUA_N':'sum',
                                                                'DM_CORTO_ELE': 'sum',
                                                                'DM_FUGAS_N': 'sum'}).reset_index())
COLONIA_FISICO = CONC_DIS(FISICO_COL, 'CVE_COL','FISICO_COL')
COLONIA_FISICO.head(2)
```


```{python}
#| eval: true
#|

### Social a nivel Municipal

SOCIAL_MUN = pd.DataFrame(CATEGORIAS_DMY.groupby(['MUN']).agg({'DM_DROGADO': 'sum',
                                                               'DM_EBRIO':'sum',
                                                               'DM_ESCANDALO': 'sum',
                                                               'DM_FIESTA':'sum',
                                                               'DM_BASURA_P': 'sum',
                                                               'DM_PERSO_R': 'sum'}).reset_index())

MUNI_SOCIAL = CONC_DIS(SOCIAL_MUN, 'MUN', 'SOCIAL_MUN')
MUNI_SOCIAL.head(2)
```

```{python}
#| eval: true
#|
### Fisico a nivel colonia 

FISICO_MUN = pd.DataFrame(CATEGORIAS_DMY.groupby(['MUN']).agg({'DM_VEHICULO': 'sum',
                                                               'DM_GRAFITI':'sum',
                                                               'DM_AGUA_P': 'sum',
                                                               'DM_AGUA_N':'sum',
                                                               'DM_CORTO_ELE': 'sum',
                                                               'DM_FUGAS_N': 'sum'}).reset_index())
MUNI_FISICO = CONC_DIS(FISICO_MUN, 'MUN','FISICO_MUN')
MUNI_FISICO.head(2)
```

**UNION DE RESULTADOS**

```{python}
#| eval: true
#|
### Resultados Concentración de desventajas + Desorden Social + Desorden Físico
### NIVEL COLONIA 

COLONIA_RESULTADOS = DESVE_COL.merge(COLONIA_SOCIAL, 
                                     left_on = 'CVE_COL', 
                                     right_on = 'CVE_COL', 
                                     how = 'left').merge(COLONIA_FISICO,
                                                          left_on = 'CVE_COL',
                                                          right_on = 'CVE_COL',
                                                          how = 'left')

COLONIA_RESULTADOS.head(5)
```


```{python}
#| eval: true
#|
### Resultados Concentración de desventajas + Desorden Social + Desorden Físico
### NIVEL ALCALDIA 

ALCALDIA_RESULTADOS = DESVE_ALCA.merge(MUNI_SOCIAL, 
                                       left_on = 'MUN', 
                                       right_on = 'MUN', 
                                       how = 'left').merge(MUNI_FISICO,
                                                           left_on = 'MUN',
                                                           right_on = 'MUN',
                                                           how = 'left')

ALCALDIA_RESULTADOS.head(5)
```

# VARIABLES DE CONTROL [Colonias y Alcaldias]

**METRO**

```{python}
#| eval: true
#|
METRO_CDMX = gpd.read_file(Entradas +'STC_Metro.json').to_crs(6362)
METRO_CDMX = METRO_CDMX[['CVE_EST','geometry']]
METRO_CDMX.head(2)
```

```{python}
#| eval: true
#|
base = COLONIAS_CDMX.plot(color ='black',figsize=(5,5))
METRO_CDMX.plot(ax = base, color = 'red', markersize = 2, figsize=(5,5))
```



```{python}
#| eval: true
#|
METRO_CDMX = gpd.sjoin(COLONIAS_CDMX, 
                        METRO_CDMX[['CVE_EST','geometry']], 
                         how = "inner", 
                         op = 'contains').rename({'CVEDT': 'MUN', 
                                                  'CVE_EST': 'METRO'}, axis = 1)
METRO_CDMX.head(2)
```


```{python}
#| eval: true
#|
METRO_COL = pd.DataFrame(METRO_CDMX.groupby(['CVE_COL']).agg({'METRO':'count'}).reset_index())
METRO_MUN = pd.DataFrame(METRO_CDMX.groupby(['MUN']).agg({'METRO':'count'}).reset_index())
```

```{python}
#| eval: true
#|
### Resultados Concentración de desventajas + Desorden Social + Desorden Físico + METRO
### NIVEL COLONIA 

COLONIA_RESULTADOS = COLONIA_RESULTADOS.merge(METRO_COL, 
                                              left_on = 'CVE_COL', 
                                              right_on = 'CVE_COL',
                                              how = 'left')
COLONIA_RESULTADOS.head(5)
```


```{python}
#| eval: true
#|
### Resultados Concentración de desventajas + Desorden Social + Desorden Físico + METRO
### NIVEL ALCALDIA 

ALCALDIA_RESULTADOS = ALCALDIA_RESULTADOS.merge(METRO_MUN,
                                                left_on = 'MUN',
                                                right_on = 'MUN',
                                                how = 'left')
ALCALDIA_RESULTADOS.head(5)
```

**METROBUS**



```{python}
#| eval: true
#|

METROBUS_CDMX = gpd.read_file(Entradas +'STC_MetroBus.json').drop(['id', 'description', 
                                                                   'styleUrl', 'stroke-opacity', 'stroke',
                                                                   'icon-opacity', 'icon-color', 'icon-scale', 
                                                                   'icon'], axis = 1).to_crs(6362)
METROBUS_CDMX.head(2)

```


```{python}
#| eval: true
#|

base = COLONIAS_CDMX.plot(color ='black',figsize=(5,5))
METROBUS_CDMX.plot(ax = base, color = 'red', markersize = 2, figsize=(5,5))

```

```{python}
#| eval: true
#|
METROBUS_CDMX = gpd.sjoin(COLONIAS_CDMX, 
                          METROBUS_CDMX[['CVE_EST','geometry']], 
                          how = "inner", 
                          op = 'contains').rename({'CVEDT': 'MUN', 
                                                   'CVE_EST': 'METROBUS'}, axis = 1)
METROBUS_CDMX.head(2)
```

```{python}
#| eval: true
#|
METROBUS_COL = pd.DataFrame(METROBUS_CDMX.groupby(['CVE_COL']).agg({'METROBUS':'count'}).reset_index())
METROBUS_MUN = pd.DataFrame(METROBUS_CDMX.groupby(['MUN']).agg({'METROBUS':'count'}).reset_index())
```

```{python}
#| eval: true
#|
### Resultados Concentración de desventajas + Desorden Social + Desorden Físico + METRO + METROBUS
### NIVEL COLONIA 

COLONIA_RESULTADOS = COLONIA_RESULTADOS.merge(METROBUS_COL, 
                                              left_on = 'CVE_COL', 
                                              right_on = 'CVE_COL',
                                              how = 'left')
COLONIA_RESULTADOS.head(2)
```

```{python}
#| eval: true
#|
### Resultados Concentración de desventajas + Desorden Social + Desorden Físico + METRO + METROBUS
### NIVEL ALCALDIA 

ALCALDIA_RESULTADOS = ALCALDIA_RESULTADOS.merge(METROBUS_MUN,
                                                left_on = 'MUN',
                                                right_on = 'MUN',
                                                how = 'left')
ALCALDIA_RESULTADOS.head(5)
```